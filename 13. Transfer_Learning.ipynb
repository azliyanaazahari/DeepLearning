{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEBwvfDEbMrb"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "2lF5IkES-CAC",
        "outputId": "d35f4aaf-8186-4e42-dd3e-06cf23809721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May 13 04:47:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8             12W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pW1hKzCbMri"
      },
      "source": [
        "## Pytorch Transfer Learning\n",
        "\n",
        "We've built a few models by hand so far.\n",
        "\n",
        "But their performance has been poor.\n",
        "\n",
        "You might be thinking, is there a well-performing model that already exists for our problem?\n",
        "\n",
        "And in the world of deep learning, the answer is often yes.\n",
        "\n",
        "We'll see how by using a powerful technique called transfer learning.\n",
        "\n",
        "In this notebook, you will learn how to train a convolutional neural network for\n",
        "image classification using transfer learning. You can read more about the transfer\n",
        "learning at `cs231n notes <https://cs231n.github.io/transfer-learning/>`__\n",
        "\n",
        "Quoting these notes,\n",
        "\n",
        "    In practice, very few people train an entire Convolutional Network\n",
        "    from scratch (with random initialization), because it is relatively\n",
        "    rare to have a dataset of sufficient size. Instead, it is common to\n",
        "    pretrain a ConvNet on a very large dataset (e.g. ImageNet, which\n",
        "    contains 1.2 million images with 1000 categories), and then use the\n",
        "    ConvNet either as an initialization or a fixed feature extractor for\n",
        "    the task of interest.\n",
        "\n",
        "\n",
        "## What is transfer learning?\n",
        "\n",
        "**Transfer learning** allows us to take the patterns (also called weights) another model has learned from another problem and use them for our own problem.\n",
        "\n",
        "For example, we can take the patterns a computer vision model has learned from datasets such as [ImageNet](https://www.image-net.org/) (millions of images of different objects) and use them to train new model on CIFAR10.\n",
        "\n",
        "Or we could take the patterns from a [language model](https://developers.google.com/machine-learning/glossary#masked-language-model) (a model that's been through large amounts of text to learn a representation of language) and use them as the basis of a model to classify different text samples.\n",
        "\n",
        "The premise remains: find a well-performing existing model and apply it to your own problem.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/06-transfer-learning-example-overview.png\" alt=\"transfer learning overview on different problems\" width=900/>\n",
        "\n",
        "*Example of transfer learning being applied to computer vision and natural language processing (NLP). In the case of computer vision, a computer vision model might learn patterns on millions of images in ImageNet and then use those patterns to infer on another problem. And for NLP, a language model may learn the structure of language by reading all of Wikipedia (and perhaps more) and then apply that knowledge to a different problem.*\n",
        "\n",
        "\n",
        "## Where to find pretrained models\n",
        "\n",
        "The world of deep learning is an amazing place.\n",
        "\n",
        "So amazing that many people around the world share their work.\n",
        "\n",
        "Often, code and pretrained models for the latest state-of-the-art research is released within a few days of publishing.\n",
        "\n",
        "And there are several places you can find pretrained models to use for your own problems.\n",
        "\n",
        "| **Location** | **What's there?** | **Link(s)** |\n",
        "| ----- | ----- | ----- |\n",
        "| **PyTorch domain libraries** | Each of the PyTorch domain libraries (`torchvision`, `torchtext`) come with pretrained models of some form. The models there work right within PyTorch. | [`torchvision.models`](https://pytorch.org/vision/stable/models.html), [`torchtext.models`](https://pytorch.org/text/main/models.html), [`torchaudio.models`](https://pytorch.org/audio/stable/models.html), [`torchrec.models`](https://pytorch.org/torchrec/torchrec.models.html) |\n",
        "| **HuggingFace Hub** | A series of pretrained models on many different domains (vision, text, audio and more) from organizations around the world. There's plenty of different datasets too. | https://huggingface.co/models, https://huggingface.co/datasets |\n",
        "| **`timm` (PyTorch Image Models) library** | Almost all of the latest and greatest computer vision models in PyTorch code as well as plenty of other helpful computer vision features. | https://github.com/rwightman/pytorch-image-models|\n",
        "| **Paperswithcode** | A collection of the latest state-of-the-art machine learning papers with code implementations attached. You can also find benchmarks here of model performance on different tasks. | https://paperswithcode.com/ |\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/06-transfer-learning-where-to-find-pretrained-models.png\" alt=\"different locations to find pretrained neural network models\" width=900/>\n",
        "\n",
        "*With access to such high-quality resources as above, it should be common practice at the start of every deep learning problem you take on to ask, \"Does a pretrained model exist for my problem?\"*\n",
        "\n",
        "> **Exercise:** Spend 5-minutes going through [`torchvision.models`](https://pytorch.org/vision/stable/models.html) as well as the [HuggingFace Hub Models page](https://huggingface.co/models), what do you find? (there's no right answers here, it's just to practice exploring)\n",
        "\n",
        "\n",
        "These two major transfer learning scenarios look as follows:\n",
        "\n",
        "-  **Finetuning the convnet**: Instead of random initialization, we\n",
        "   initialize the network with a pretrained network, like the one that is\n",
        "   trained on imagenet 1000 dataset. Rest of the training looks as\n",
        "   usual.\n",
        "-  **ConvNet as fixed feature extractor**: Here, we will freeze the weights\n",
        "   for all of the network except that of the final fully connected\n",
        "   layer. This last fully connected layer is replaced with a new one\n",
        "   with random weights and only this layer is trained.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V1CkAbw0bMrn",
        "outputId": "6432d3e4-6a0c-4bb2-dab1-b5481f596853",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDLpHs_ZbMrp"
      },
      "source": [
        "## 1. Load Data\n",
        "---------\n",
        "\n",
        "Before we can start to use **transfer learning**, we'll need a dataset.\n",
        "\n",
        "To see how transfer learning compares to our previous attempts at model building, we'll use the same CIFAR10 for experimentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root='./data', train=True, transform=None, download=True):\n",
        "        self.data = torchvision.datasets.CIFAR10(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]  # Returns (image, label) tuple\n",
        "\n",
        "def get_dataloader(batch_size=32, num_workers=2, root='./data'):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10Dataset(root=root, train=True, transform=transform)\n",
        "    test_dataset = CIFAR10Dataset(root=root, train=False, transform=transform)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "# Get dataloaders\n",
        "train_dataloader, test_dataloader = get_dataloader(batch_size=32, num_workers=2)\n",
        "\n",
        "# Define class names\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "batch_size = 16"
      ],
      "metadata": {
        "id": "VB20BsOb6fOX",
        "outputId": "b738a378-3118-4349-8d40-ac778bdedb9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzBJhridbMrr"
      },
      "source": [
        "## 2. Define the training loop\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "16shNGOgbMrs"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def train_and_validate(model, loss_criterion, optimizer, train_dataloader, test_dataloader, epochs=25, device='cuda'):\n",
        "    '''\n",
        "    Function to train and validate\n",
        "    Parameters\n",
        "        :param model: Model to train and validate\n",
        "        :param loss_criterion: Loss Criterion to minimize\n",
        "        :param optimizer: Optimizer for computing gradients\n",
        "        :param train_dataloader: DataLoader for training data\n",
        "        :param test_dataloader: DataLoader for test/validation data\n",
        "        :param epochs: Number of epochs (default=25)\n",
        "        :param device: Device to perform computations ('cuda' or 'cpu')\n",
        "\n",
        "    Returns\n",
        "        model: Trained Model with best validation accuracy\n",
        "        history: (dict object): Having training loss, accuracy and validation loss, accuracy\n",
        "    '''\n",
        "\n",
        "    start = time.time()\n",
        "    history = []\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # accuracy = torchmetrics.Accuracy(device=device)\n",
        "    # Initialize the accuracy metric from torchmetrics\n",
        "    # accuracy = torchmetrics.classification.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        epoch_start = time.time()\n",
        "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        train_loss = 0.0\n",
        "        train_acc = 0.0\n",
        "\n",
        "        valid_loss = 0.0\n",
        "        valid_acc = 0.0\n",
        "\n",
        "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Clean existing gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass - compute outputs on input data using the model\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagate the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute the total loss for the batch and add it to train_loss\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            # Compute the accuracy\n",
        "            ret, predictions = torch.max(outputs.data, 1)\n",
        "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "            # Convert correct_counts to float and then compute the mean\n",
        "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "            # Compute total accuracy in the whole batch and add to train_acc\n",
        "            train_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "        # Validation - No gradient tracking needed\n",
        "        with torch.no_grad():\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            # Validation loop\n",
        "            for j, (inputs, labels) in enumerate(test_dataloader):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass - compute outputs on input data using the model\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                # Compute loss\n",
        "                loss = loss_criterion(outputs, labels)\n",
        "\n",
        "                # Compute the total loss for the batch and add it to valid_loss\n",
        "                valid_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                # Calculate validation accuracy\n",
        "                ret, predictions = torch.max(outputs.data, 1)\n",
        "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
        "\n",
        "                # Convert correct_counts to float and then compute the mean\n",
        "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
        "\n",
        "                # Compute total accuracy in the whole batch and add to valid_acc\n",
        "                valid_acc += acc.item() * inputs.size(0)\n",
        "\n",
        "\n",
        "        # Find average training loss and training accuracy\n",
        "        avg_train_loss = train_loss / len(train_dataloader.dataset)\n",
        "        avg_train_acc = train_acc / len(train_dataloader.dataset)\n",
        "\n",
        "        # Find average validation loss and training accuracy\n",
        "        avg_test_loss = valid_loss / len(test_dataloader.dataset)\n",
        "        avg_test_acc = valid_acc / len(test_dataloader.dataset)\n",
        "\n",
        "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
        "\n",
        "        epoch_end = time.time()\n",
        "\n",
        "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\tValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc * 100, avg_test_loss, avg_test_acc * 100, epoch_end - epoch_start))\n",
        "\n",
        "        # Save if the model has best accuracy till now\n",
        "        if avg_test_acc > best_acc:\n",
        "            best_acc = avg_test_acc\n",
        "            best_model = model\n",
        "            torch.save(best_model, 'best_model.pt')\n",
        "\n",
        "    return best_model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sWYeYbAbMrw"
      },
      "source": [
        "## 3. Finetuning the convnet\n",
        "----------------------\n",
        "\n",
        "Load a pretrained model and define a **NEW** final fully connected layer.\n",
        "\n",
        "Since we're working on a computer vision problem, we can find pretrained classification models in [`torchvision.models`](https://pytorch.org/vision/stable/models.html#classification).\n",
        "\n",
        "Exploring the documentation, you'll find plenty of common computer vision architecture backbones such as:\n",
        "\n",
        "| **Architecuture backbone** | **Code** |\n",
        "| ----- | ----- |\n",
        "| [ResNet](https://arxiv.org/abs/1512.03385)'s | `torchvision.models.resnet18()`, `torchvision.models.resnet50()`... |\n",
        "| [VGG](https://arxiv.org/abs/1409.1556) (similar to what we used for TinyVGG) | `torchvision.models.vgg16()` |\n",
        "| [EfficientNet](https://arxiv.org/abs/1905.11946)'s | `torchvision.models.efficientnet_b0()`, `torchvision.models.efficientnet_b1()`... |\n",
        "| [VisionTransformer](https://arxiv.org/abs/2010.11929) (ViT's)| `torchvision.models.vit_b_16()`, `torchvision.models.vit_b_32()`... |\n",
        "| [ConvNeXt](https://arxiv.org/abs/2201.03545) | `torchvision.models.convnext_tiny()`,  `torchvision.models.convnext_small()`... |\n",
        "| More available in `torchvision.models` | `torchvision.models...` |\n",
        "\n",
        "### 3.1 Which pretrained model should you use?\n",
        "\n",
        "It depends on your problem/the device you're working with.\n",
        "\n",
        "Generally, the higher number in the model name (e.g. `resnet18()` -> `resnet50()` -> `resnet152()`) means *better performance* but a *larger* model.\n",
        "\n",
        "You might think better performance is *always better*, right?\n",
        "\n",
        "That's true but **some better performing models are too big for some devices**.\n",
        "\n",
        "For example, say you'd like to run your model on a mobile-device, you'll have to take into account the limited compute resources on the device, thus you'd be looking for a smaller model.\n",
        "\n",
        "But if you've got unlimited compute power, you'd likely take the biggest, most compute hungry model you can.\n",
        "\n",
        "Understanding this **performance vs. speed vs. size tradeoff** will come with time and practice.\n",
        "\n",
        "For example, a nice balance can be found in the `efficientnet_bX` models.\n",
        "\n",
        "As of May 2022, [Nutrify](https://nutrify.app) (the machine learning powered app I'm working on) is powered by an `efficientnet_b0`.\n",
        "\n",
        "[Comma.ai](https://comma.ai/) (a company that makes open source self-driving car software) [uses an `efficientnet_b2`](https://geohot.github.io/blog/jekyll/update/2021/10/29/an-architecture-for-life.html) to learn a representation of the road."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Setting up a pretrained model\n",
        "\n",
        "The pretrained model we're going to be using is [`torchvision.models.resnet18()`](https://pytorch.org/vision/master/models/generated/torchvision.models.resnet18.html#torchvision.models.resnet18).\n",
        "\n",
        "The architecture is from the paper *[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)*.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/06-effnet-b0-feature-extractor.png\" alt=\"efficienet_b0 from PyTorch torchvision feature extraction model\" width=900/>\n",
        "\n",
        "*Example of what we're going to create, a pretrained resnet18 from `torchvision.models` with the output layer adjusted for our use case of classifying objects in CIFAR10."
      ],
      "metadata": {
        "id": "tPuFhkHQlcm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let say we are using the Resnet 18 as our pretrained model. We can download and visualize the layers:"
      ],
      "metadata": {
        "id": "lnfAH-_auHBc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0SyIHmRpbMrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5424e5c9-0a95-4226-ab00-edd5bdd117e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 199MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "model_ft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model_ft,\n",
        "        input_size=(1, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0aBkxgcVlIi",
        "outputId": "e44f033b-96a5-47d5-b91e-036f318cc173"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "ResNet (ResNet)                          [1, 3, 224, 224]     [1, 1000]            --                   True\n",
              "├─Conv2d (conv1)                         [1, 3, 224, 224]     [1, 64, 112, 112]    9,408                True\n",
              "├─BatchNorm2d (bn1)                      [1, 64, 112, 112]    [1, 64, 112, 112]    128                  True\n",
              "├─ReLU (relu)                            [1, 64, 112, 112]    [1, 64, 112, 112]    --                   --\n",
              "├─MaxPool2d (maxpool)                    [1, 64, 112, 112]    [1, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
              "│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    └─BasicBlock (1)                    [1, 64, 56, 56]      [1, 64, 56, 56]      --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 64, 56, 56]      [1, 64, 56, 56]      36,864               True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 64, 56, 56]      [1, 64, 56, 56]      128                  True\n",
              "│    │    └─ReLU (relu)                  [1, 64, 56, 56]      [1, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer2)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   True\n",
              "│    └─BasicBlock (0)                    [1, 64, 56, 56]      [1, 128, 28, 28]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 64, 56, 56]      [1, 128, 28, 28]     73,728               True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─Sequential (downsample)      [1, 64, 56, 56]      [1, 128, 28, 28]     8,448                True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    └─BasicBlock (1)                    [1, 128, 28, 28]     [1, 128, 28, 28]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 128, 28, 28]     [1, 128, 28, 28]     147,456              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 128, 28, 28]     [1, 128, 28, 28]     256                  True\n",
              "│    │    └─ReLU (relu)                  [1, 128, 28, 28]     [1, 128, 28, 28]     --                   --\n",
              "├─Sequential (layer3)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   True\n",
              "│    └─BasicBlock (0)                    [1, 128, 28, 28]     [1, 256, 14, 14]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 128, 28, 28]     [1, 256, 14, 14]     294,912              True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─Sequential (downsample)      [1, 128, 28, 28]     [1, 256, 14, 14]     33,280               True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    └─BasicBlock (1)                    [1, 256, 14, 14]     [1, 256, 14, 14]     --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 256, 14, 14]     [1, 256, 14, 14]     589,824              True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 256, 14, 14]     [1, 256, 14, 14]     512                  True\n",
              "│    │    └─ReLU (relu)                  [1, 256, 14, 14]     [1, 256, 14, 14]     --                   --\n",
              "├─Sequential (layer4)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   True\n",
              "│    └─BasicBlock (0)                    [1, 256, 14, 14]     [1, 512, 7, 7]       --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 256, 14, 14]     [1, 512, 7, 7]       1,179,648            True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─Sequential (downsample)      [1, 256, 14, 14]     [1, 512, 7, 7]       132,096              True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    └─BasicBlock (1)                    [1, 512, 7, 7]       [1, 512, 7, 7]       --                   True\n",
              "│    │    └─Conv2d (conv1)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            True\n",
              "│    │    └─BatchNorm2d (bn1)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [1, 512, 7, 7]       [1, 512, 7, 7]       2,359,296            True\n",
              "│    │    └─BatchNorm2d (bn2)            [1, 512, 7, 7]       [1, 512, 7, 7]       1,024                True\n",
              "│    │    └─ReLU (relu)                  [1, 512, 7, 7]       [1, 512, 7, 7]       --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [1, 512, 7, 7]       [1, 512, 1, 1]       --                   --\n",
              "├─Linear (fc)                            [1, 512]             [1, 1000]            513,000              True\n",
              "========================================================================================================================\n",
              "Total params: 11,689,512\n",
              "Trainable params: 11,689,512\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 1.81\n",
              "========================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 39.75\n",
              "Params size (MB): 46.76\n",
              "Estimated Total Size (MB): 87.11\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our main objective is to **REPLACE** the final classification layer (containing 1000 classes of Imagenet) with a **NEW** classification layer (containing 10, corresponding to 10 classes in CIFAR10)\n",
        "\n",
        "Therefore, we are accessing the in_features of the fc (fully connected) layer and connect it to a newly defined layer containing 10 neurons:"
      ],
      "metadata": {
        "id": "9Xmo2Dwkuf2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 10.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(train_data.classes)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "# LOSS AND OPTIMIZER\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model_ft = model_ft.to(device)"
      ],
      "metadata": {
        "id": "F80BdM7auS5_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THo1KYFMbMry"
      },
      "source": [
        "### Train and evaluate\n",
        "\n",
        "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
        "minute.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ifwbrqKqbMrz",
        "outputId": "e194de6e-24f2-4a7c-e4b2-cd758511dee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "95cb1f100f4d4b458e73a66c4f300651",
            "88b498dd069d41519106ee55a67db0c5",
            "40ad7adb32094bcba5d656e2c9022654",
            "65e639d850db4b9891ad23fbef5cd824",
            "e3114ea74e534559b375b25a297ed14d",
            "23ad7d11c4574a83b4b9ad5f19079313",
            "c9ea387d53824a4384e16117f2ef9a82",
            "a589279856db4af8b5fc26cb4bd8a518",
            "2ea48d00ced94fb69a346547da24d282",
            "fdecb0bccf4c48c1bccc4993b57f39e0",
            "f47e226a5f07477ab6f01d8863cc0b62"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95cb1f100f4d4b458e73a66c4f300651"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5\n",
            "Epoch : 000, Training: Loss: 0.9787, Accuracy: 65.4660%, \n",
            "\t\tValidation : Loss : 0.8395, Accuracy: 71.0200%, Time: 177.0288s\n",
            "Epoch: 2/5\n",
            "Epoch : 001, Training: Loss: 0.6521, Accuracy: 77.3440%, \n",
            "\t\tValidation : Loss : 0.6906, Accuracy: 76.5000%, Time: 176.7414s\n",
            "Epoch: 3/5\n",
            "Epoch : 002, Training: Loss: 0.5283, Accuracy: 81.6140%, \n",
            "\t\tValidation : Loss : 0.6063, Accuracy: 78.9900%, Time: 175.3848s\n",
            "Epoch: 4/5\n",
            "Epoch : 003, Training: Loss: 0.4394, Accuracy: 84.6720%, \n",
            "\t\tValidation : Loss : 0.6605, Accuracy: 78.2600%, Time: 175.8664s\n",
            "Epoch: 5/5\n",
            "Epoch : 004, Training: Loss: 0.3685, Accuracy: 87.2400%, \n",
            "\t\tValidation : Loss : 0.6800, Accuracy: 77.4800%, Time: 175.6715s\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "trained_model, history = train_and_validate(model_ft, loss_fn, optimizer, train_dataloader, test_dataloader, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyze the loss curve\n",
        "\n",
        "def plot_loss(history):\n",
        "  history = np.array(history)\n",
        "  plt.plot(history[:,0:2])\n",
        "  plt.legend(['Tr Loss', 'Val Loss'])\n",
        "  plt.xlabel('Epoch Number')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.ylim(0,3)\n",
        "  # plt.savefig('cifar10_loss_curve.png')\n",
        "  plt.show()\n",
        "\n",
        "def plot_accuracy(history):\n",
        "  history = np.array(history)\n",
        "  plt.plot(history[:,2:4])\n",
        "  plt.legend(['Tr Accuracy', 'Val Accuracy'])\n",
        "  plt.xlabel('Epoch Number')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.ylim(0,1)\n",
        "  # plt.savefig('cifar10_accuracy_curve.png')\n",
        "  plt.show()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "def plot_confusionMatrix(model, test_dataloader):\n",
        "\n",
        "  y_pred = []\n",
        "  y_true = []\n",
        "\n",
        "  model.to('cpu')\n",
        "\n",
        "  # iterate over test data\n",
        "  for inputs, labels in test_dataloader:\n",
        "          output = model(inputs) # Feed Network\n",
        "\n",
        "          output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "          y_pred.extend(output) # Save Prediction\n",
        "\n",
        "          labels = labels.data.cpu().numpy()\n",
        "          y_true.extend(labels) # Save Truth\n",
        "\n",
        "  # Build confusion matrix\n",
        "  cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "  df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in class_names],\n",
        "                      columns = [i for i in class_names])\n",
        "  plt.figure(figsize = (20,10))\n",
        "  sn.heatmap(df_cm, annot=True)\n",
        "  # plt.savefig('output.png')"
      ],
      "metadata": {
        "id": "_urjGvYzX3E2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mEcXbXkIbMrz",
        "outputId": "8159cb74-e383-493e-a68f-b30af37e2552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 893
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_loss(history)\n",
        "plot_accuracy(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusionMatrix(trained_model, test_dataloader)"
      ],
      "metadata": {
        "id": "swmdaXjdY2Xa",
        "outputId": "823024a8-b968-4c86-d105-dcba8fd402e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5de86ef8484c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_confusionMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-ed0ee3710cca>\u001b[0m in \u001b[0;36mplot_confusionMatrix\u001b[0;34m(model, test_dataloader)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;31m# iterate over test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Feed Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edk51HbqbMr0"
      },
      "source": [
        "ConvNet as fixed feature extractor\n",
        "----------------------------------\n",
        "\n",
        "Here, we need to freeze all the network except the final layer. We need\n",
        "to set ``requires_grad = False`` to freeze the parameters so that the\n",
        "gradients are not computed in ``backward()``.\n",
        "\n",
        "You can read more about this in the documentation\n",
        "`here <https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward>`__.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model_conv = model_conv.to(device)"
      ],
      "metadata": {
        "id": "Wy2MNxvzkRfi",
        "outputId": "5f0d21f4-308f-4c58-b6d5-1f806e9c26ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS AND OPTIMIZER\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model_conv = model_conv.to(device)"
      ],
      "metadata": {
        "id": "rtecEFD4kSaw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model_conv,\n",
        "        input_size=(4, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ],
      "metadata": {
        "id": "BwuY5c6UmiiE",
        "outputId": "4d6f7afc-fede-449c-81b3-e3a0d9c53726",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "========================================================================================================================\n",
              "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
              "========================================================================================================================\n",
              "ResNet (ResNet)                          [4, 3, 224, 224]     [4, 10]              --                   Partial\n",
              "├─Conv2d (conv1)                         [4, 3, 224, 224]     [4, 64, 112, 112]    (9,408)              False\n",
              "├─BatchNorm2d (bn1)                      [4, 64, 112, 112]    [4, 64, 112, 112]    (128)                False\n",
              "├─ReLU (relu)                            [4, 64, 112, 112]    [4, 64, 112, 112]    --                   --\n",
              "├─MaxPool2d (maxpool)                    [4, 64, 112, 112]    [4, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer1)                    [4, 64, 56, 56]      [4, 64, 56, 56]      --                   False\n",
              "│    └─BasicBlock (0)                    [4, 64, 56, 56]      [4, 64, 56, 56]      --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 64, 56, 56]      [4, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 64, 56, 56]      [4, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [4, 64, 56, 56]      [4, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 64, 56, 56]      [4, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 64, 56, 56]      [4, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [4, 64, 56, 56]      [4, 64, 56, 56]      --                   --\n",
              "│    └─BasicBlock (1)                    [4, 64, 56, 56]      [4, 64, 56, 56]      --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 64, 56, 56]      [4, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 64, 56, 56]      [4, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [4, 64, 56, 56]      [4, 64, 56, 56]      --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 64, 56, 56]      [4, 64, 56, 56]      (36,864)             False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 64, 56, 56]      [4, 64, 56, 56]      (128)                False\n",
              "│    │    └─ReLU (relu)                  [4, 64, 56, 56]      [4, 64, 56, 56]      --                   --\n",
              "├─Sequential (layer2)                    [4, 64, 56, 56]      [4, 128, 28, 28]     --                   False\n",
              "│    └─BasicBlock (0)                    [4, 64, 56, 56]      [4, 128, 28, 28]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 64, 56, 56]      [4, 128, 28, 28]     (73,728)             False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 128, 28, 28]     [4, 128, 28, 28]     (256)                False\n",
              "│    │    └─ReLU (relu)                  [4, 128, 28, 28]     [4, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 128, 28, 28]     [4, 128, 28, 28]     (147,456)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 128, 28, 28]     [4, 128, 28, 28]     (256)                False\n",
              "│    │    └─Sequential (downsample)      [4, 64, 56, 56]      [4, 128, 28, 28]     (8,448)              False\n",
              "│    │    └─ReLU (relu)                  [4, 128, 28, 28]     [4, 128, 28, 28]     --                   --\n",
              "│    └─BasicBlock (1)                    [4, 128, 28, 28]     [4, 128, 28, 28]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 128, 28, 28]     [4, 128, 28, 28]     (147,456)            False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 128, 28, 28]     [4, 128, 28, 28]     (256)                False\n",
              "│    │    └─ReLU (relu)                  [4, 128, 28, 28]     [4, 128, 28, 28]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 128, 28, 28]     [4, 128, 28, 28]     (147,456)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 128, 28, 28]     [4, 128, 28, 28]     (256)                False\n",
              "│    │    └─ReLU (relu)                  [4, 128, 28, 28]     [4, 128, 28, 28]     --                   --\n",
              "├─Sequential (layer3)                    [4, 128, 28, 28]     [4, 256, 14, 14]     --                   False\n",
              "│    └─BasicBlock (0)                    [4, 128, 28, 28]     [4, 256, 14, 14]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 128, 28, 28]     [4, 256, 14, 14]     (294,912)            False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 256, 14, 14]     [4, 256, 14, 14]     (512)                False\n",
              "│    │    └─ReLU (relu)                  [4, 256, 14, 14]     [4, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 256, 14, 14]     [4, 256, 14, 14]     (589,824)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 256, 14, 14]     [4, 256, 14, 14]     (512)                False\n",
              "│    │    └─Sequential (downsample)      [4, 128, 28, 28]     [4, 256, 14, 14]     (33,280)             False\n",
              "│    │    └─ReLU (relu)                  [4, 256, 14, 14]     [4, 256, 14, 14]     --                   --\n",
              "│    └─BasicBlock (1)                    [4, 256, 14, 14]     [4, 256, 14, 14]     --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 256, 14, 14]     [4, 256, 14, 14]     (589,824)            False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 256, 14, 14]     [4, 256, 14, 14]     (512)                False\n",
              "│    │    └─ReLU (relu)                  [4, 256, 14, 14]     [4, 256, 14, 14]     --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 256, 14, 14]     [4, 256, 14, 14]     (589,824)            False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 256, 14, 14]     [4, 256, 14, 14]     (512)                False\n",
              "│    │    └─ReLU (relu)                  [4, 256, 14, 14]     [4, 256, 14, 14]     --                   --\n",
              "├─Sequential (layer4)                    [4, 256, 14, 14]     [4, 512, 7, 7]       --                   False\n",
              "│    └─BasicBlock (0)                    [4, 256, 14, 14]     [4, 512, 7, 7]       --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 256, 14, 14]     [4, 512, 7, 7]       (1,179,648)          False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 512, 7, 7]       [4, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─ReLU (relu)                  [4, 512, 7, 7]       [4, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 512, 7, 7]       [4, 512, 7, 7]       (2,359,296)          False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 512, 7, 7]       [4, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─Sequential (downsample)      [4, 256, 14, 14]     [4, 512, 7, 7]       (132,096)            False\n",
              "│    │    └─ReLU (relu)                  [4, 512, 7, 7]       [4, 512, 7, 7]       --                   --\n",
              "│    └─BasicBlock (1)                    [4, 512, 7, 7]       [4, 512, 7, 7]       --                   False\n",
              "│    │    └─Conv2d (conv1)               [4, 512, 7, 7]       [4, 512, 7, 7]       (2,359,296)          False\n",
              "│    │    └─BatchNorm2d (bn1)            [4, 512, 7, 7]       [4, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─ReLU (relu)                  [4, 512, 7, 7]       [4, 512, 7, 7]       --                   --\n",
              "│    │    └─Conv2d (conv2)               [4, 512, 7, 7]       [4, 512, 7, 7]       (2,359,296)          False\n",
              "│    │    └─BatchNorm2d (bn2)            [4, 512, 7, 7]       [4, 512, 7, 7]       (1,024)              False\n",
              "│    │    └─ReLU (relu)                  [4, 512, 7, 7]       [4, 512, 7, 7]       --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)            [4, 512, 7, 7]       [4, 512, 1, 1]       --                   --\n",
              "├─Linear (fc)                            [4, 512]             [4, 10]              5,130                True\n",
              "========================================================================================================================\n",
              "Total params: 11,181,642\n",
              "Trainable params: 5,130\n",
              "Non-trainable params: 11,176,512\n",
              "Total mult-adds (Units.GIGABYTES): 7.25\n",
              "========================================================================================================================\n",
              "Input size (MB): 2.41\n",
              "Forward/backward pass size (MB): 158.96\n",
              "Params size (MB): 44.73\n",
              "Estimated Total Size (MB): 206.09\n",
              "========================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvY-zKkKbMr1"
      },
      "source": [
        "Train and evaluate\n",
        "^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "On CPU this will take about half the time compared to previous scenario.\n",
        "This is expected as gradients don't need to be computed for most of the\n",
        "network. However, forward does need to be computed.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLs3EULwbMr1",
        "outputId": "5323814b-9307-497b-a451-8888846987b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "e4734ff6e2674f8f8b0bdb429347d0ec",
            "154be9cd3e9242ff88aa8931b7559082",
            "afa62399be024226ac84651ed63d7f21",
            "433a62a329d0491d96b4025f788ce6e9",
            "bd9632ee9aa645d4908d1234dd09dc97",
            "85593d2bce7f49b6a7314528603efcbe",
            "80128ebeceab475eab712e7378e3cd68",
            "8d6cb17026fd45678ed1f645d8547ba2",
            "1f7b2b39c2a6461ba619cad5287a3065",
            "523c7412e9f14c28b79a3c14e1993662",
            "90501c692370444f9b3c4725203b58b4"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4734ff6e2674f8f8b0bdb429347d0ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5\n",
            "Epoch : 000, Training: Loss: 1.7606, Accuracy: 37.2700%, \n",
            "\t\tValidation : Loss : 1.6446, Accuracy: 41.5800%, Time: 94.9336s\n",
            "Epoch: 2/5\n",
            "Epoch : 001, Training: Loss: 1.6112, Accuracy: 43.0680%, \n",
            "\t\tValidation : Loss : 1.5910, Accuracy: 44.2200%, Time: 96.0206s\n",
            "Epoch: 3/5\n",
            "Epoch : 002, Training: Loss: 1.5761, Accuracy: 44.1500%, \n",
            "\t\tValidation : Loss : 1.5518, Accuracy: 45.3900%, Time: 95.6692s\n",
            "Epoch: 4/5\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "trained_model, history = train_and_validate(model_conv, loss_fn, optimizer, train_dataloader, test_dataloader, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn-gDyEIbMr2"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)\n",
        "plot_accuracy(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusionMatrix(trained_model, test_dataloader)"
      ],
      "metadata": {
        "id": "sPWFWHNtk6hV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wesCJc-bMr3"
      },
      "source": [
        "Further Learning\n",
        "-----------------\n",
        "\n",
        "If you would like to learn more about the applications of transfer learning,\n",
        "checkout our `Quantized Transfer Learning for Computer Vision Tutorial <https://pytorch.org/tutorials/intermediate/quantized_transfer_learning_tutorial.html>`_.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation"
      ],
      "metadata": {
        "id": "u22mT4uBAw09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(batch_size=4, num_workers=0, root='./data'):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.CenterCrop(size=224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10Dataset(root=root, train=True, transform=transform)\n",
        "    test_dataset = CIFAR10Dataset(root=root, train=False, transform=transform)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "OWaWPFBeAznF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95cb1f100f4d4b458e73a66c4f300651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88b498dd069d41519106ee55a67db0c5",
              "IPY_MODEL_40ad7adb32094bcba5d656e2c9022654",
              "IPY_MODEL_65e639d850db4b9891ad23fbef5cd824"
            ],
            "layout": "IPY_MODEL_e3114ea74e534559b375b25a297ed14d"
          }
        },
        "88b498dd069d41519106ee55a67db0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ad7d11c4574a83b4b9ad5f19079313",
            "placeholder": "​",
            "style": "IPY_MODEL_c9ea387d53824a4384e16117f2ef9a82",
            "value": "100%"
          }
        },
        "40ad7adb32094bcba5d656e2c9022654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a589279856db4af8b5fc26cb4bd8a518",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ea48d00ced94fb69a346547da24d282",
            "value": 5
          }
        },
        "65e639d850db4b9891ad23fbef5cd824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdecb0bccf4c48c1bccc4993b57f39e0",
            "placeholder": "​",
            "style": "IPY_MODEL_f47e226a5f07477ab6f01d8863cc0b62",
            "value": " 5/5 [14:41&lt;00:00, 175.98s/it]"
          }
        },
        "e3114ea74e534559b375b25a297ed14d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23ad7d11c4574a83b4b9ad5f19079313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ea387d53824a4384e16117f2ef9a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a589279856db4af8b5fc26cb4bd8a518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea48d00ced94fb69a346547da24d282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fdecb0bccf4c48c1bccc4993b57f39e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f47e226a5f07477ab6f01d8863cc0b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4734ff6e2674f8f8b0bdb429347d0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_154be9cd3e9242ff88aa8931b7559082",
              "IPY_MODEL_afa62399be024226ac84651ed63d7f21",
              "IPY_MODEL_433a62a329d0491d96b4025f788ce6e9"
            ],
            "layout": "IPY_MODEL_bd9632ee9aa645d4908d1234dd09dc97"
          }
        },
        "154be9cd3e9242ff88aa8931b7559082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85593d2bce7f49b6a7314528603efcbe",
            "placeholder": "​",
            "style": "IPY_MODEL_80128ebeceab475eab712e7378e3cd68",
            "value": " 60%"
          }
        },
        "afa62399be024226ac84651ed63d7f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d6cb17026fd45678ed1f645d8547ba2",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f7b2b39c2a6461ba619cad5287a3065",
            "value": 3
          }
        },
        "433a62a329d0491d96b4025f788ce6e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_523c7412e9f14c28b79a3c14e1993662",
            "placeholder": "​",
            "style": "IPY_MODEL_90501c692370444f9b3c4725203b58b4",
            "value": " 3/5 [04:46&lt;03:11, 95.73s/it]"
          }
        },
        "bd9632ee9aa645d4908d1234dd09dc97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85593d2bce7f49b6a7314528603efcbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80128ebeceab475eab712e7378e3cd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d6cb17026fd45678ed1f645d8547ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7b2b39c2a6461ba619cad5287a3065": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "523c7412e9f14c28b79a3c14e1993662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90501c692370444f9b3c4725203b58b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}